{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from __future__ import absolute_import\n",
    "# from __future__ import division\n",
    "# from __future__ import print_function\n",
    "\n",
    "from keras.layers import Lambda, Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import argparse\n",
    "import os\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reparameterization trick\n",
    "# instead of sampling from Q(z|X), sample epsilon = N(0,I)\n",
    "# z = z_mean + sqrt(var) * epsilon\n",
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling from an isotropic unit Gaussian.\n",
    "\n",
    "    # Arguments\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "\n",
    "    # Returns\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_sigma = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean = 0 and std = 1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_sigma) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(models,\n",
    "                 data,\n",
    "                 batch_size=128,\n",
    "                 model_name=\"vae_mnist\"):\n",
    "    \"\"\"Plots labels and MNIST digits as a function of the 2D latent vector\n",
    "\n",
    "    # Arguments\n",
    "        models (tuple): encoder and decoder models\n",
    "        data (tuple): test data and label\n",
    "        batch_size (int): prediction batch size\n",
    "        model_name (string): which model is using this function\n",
    "    \"\"\"\n",
    "\n",
    "    encoder, decoder = models\n",
    "    x_test, y_test = data\n",
    "    os.makedirs(model_name, exist_ok=True)\n",
    "\n",
    "    filename = os.path.join(model_name, \"vae_mean.png\")\n",
    "    # display a 2D plot of the digit classes in the latent space\n",
    "    z_mean, _, _ = encoder.predict(x_test,\n",
    "                                   batch_size=batch_size)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.scatter(z_mean[:, 0], z_mean[:, 1], c=y_test)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "    filename = os.path.join(model_name, \"digits_over_latent.png\")\n",
    "    # display a 30x30 2D manifold of digits\n",
    "    n = 30\n",
    "    digit_size = 28\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(-4, 4, n)\n",
    "    grid_y = np.linspace(-4, 4, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = decoder.predict(z_sample)\n",
    "            digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "            figure[i * digit_size: (i + 1) * digit_size,\n",
    "                   j * digit_size: (j + 1) * digit_size] = digit\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    start_range = digit_size // 2\n",
    "    end_range = (n - 1) * digit_size + start_range + 1\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z[0]\")\n",
    "    plt.ylabel(\"z[1]\")\n",
    "    plt.imshow(figure, cmap='Greys_r')\n",
    "    plt.savefig(filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = x_train.shape[1]\n",
    "original_dim = image_size * image_size\n",
    "x_train = np.reshape(x_train, [-1, original_dim])\n",
    "x_test = np.reshape(x_test, [-1, original_dim])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network parameters\n",
    "input_shape = (original_dim, )\n",
    "intermediate_dim = 512\n",
    "batch_size = 128\n",
    "latent_dim = 2\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE model = encoder + decoder\n",
    "# build encoder model\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use reparameterization trick to push the sampling out as input\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# instantiate encoder model\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "encoder.summary()\n",
    "plot_model(encoder, to_file='vae_mlp_encoder.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build decoder model\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "outputs = Dense(original_dim, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# instantiate decoder model\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()\n",
    "plot_model(decoder, to_file='vae_mlp_decoder.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs, name='vae_mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = (encoder, decoder)\n",
    "data = (x_test, y_test)\n",
    "\n",
    "reconstruction_loss = mse(inputs, outputs)\n",
    "\n",
    "reconstruction_loss *= original_dim\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "vae.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(vae,\n",
    "            to_file='vae_mlp.png',\n",
    "            show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vae.fit(x_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, None))\n",
    "# vae.save_weights('vae_mlp_mnist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(models,\n",
    "                data,\n",
    "                batch_size=batch_size,\n",
    "                model_name=\"vae_mlp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My VAE MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras import objectives\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import os\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = pd.read_csv(\"song_list5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = songs[[\n",
    "    \"danceability\", \"energy\", \"key\", \"loudness\", \"mode\", \"speechiness\", \n",
    "    \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\", \n",
    "    \"duration_ms\", \"time_signature\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "original_dim = 13\n",
    "intermediate_dim = 32\n",
    "latent_dim = 4\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=(13,))\n",
    "h = Dense(intermediate_dim, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_sigma = Dense(latent_dim)(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon_std = 1.0\n",
    "    epsilon = K.random_normal(shape=(latent_dim,),\n",
    "                              mean=0., stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end-to-end autoencoder\n",
    "vae = Model(x, x_decoded_mean)\n",
    "\n",
    "# encoder, from inputs to latent space\n",
    "encoder = Model(x, z_mean)\n",
    "\n",
    "# generator, from latent space to reconstructed inputs\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_h_decoded = decoder_h(decoder_input)\n",
    "_x_decoded_mean = decoder_mean(_h_decoded)\n",
    "generator = Model(decoder_input, _x_decoded_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(x, x_decoded_mean):\n",
    "    xent_loss = binary_crossentropy(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n",
    "    return xent_loss + kl_loss\n",
    "\n",
    "vae.compile(optimizer='rmsprop', loss=vae_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.config.experimental_run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# x_train = x_train.astype('float32') / 255.\n",
    "# x_test = x_test.astype('float32') / 255.\n",
    "# x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "# x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "vae.fit(x_train, x_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)#,\n",
    "        # validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = pd.read_csv(\"song_list5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = songs[[\n",
    "    \"danceability\", \"energy\", \"key\", \"loudness\", \"mode\", \"speechiness\", \n",
    "    \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\", \n",
    "    \"duration_ms\", \"time_signature\"]].head(5).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(5, 13)"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[ 4.56000e-01,  2.55000e-01,  9.00000e+00, -1.58050e+01,\n         1.00000e+00,  4.80000e-02,  9.46000e-01,  1.70000e-01,\n         9.51000e-01,  5.32000e-02,  1.16424e+02,  2.53067e+05,\n         4.00000e+00],\n       [ 5.35000e-01,  8.06000e-01,  7.00000e+00, -1.02890e+01,\n         1.00000e+00,  6.42000e-02,  4.36000e-03,  1.91000e-02,\n         4.57000e-01,  3.76000e-01,  9.00890e+01,  6.37330e+04,\n         4.00000e+00],\n       [ 2.94000e-01,  4.82000e-01,  5.00000e+00, -6.40600e+00,\n         1.00000e+00,  4.30000e-02,  4.63000e-01,  0.00000e+00,\n         3.35000e-01,  2.04000e-01,  1.66693e+02,  2.55280e+05,\n         3.00000e+00],\n       [ 5.63000e-01,  6.31000e-01,  0.00000e+00, -5.14400e+00,\n         1.00000e+00,  3.24000e-02,  6.35000e-02,  8.46000e-06,\n         1.63000e-01,  5.40000e-01,  1.15657e+02,  2.54827e+05,\n         4.00000e+00],\n       [ 3.58000e-01,  6.11000e-01,  2.00000e+00, -9.75200e+00,\n         0.00000e+00,  4.54000e-02,  5.15000e-01,  4.68000e-04,\n         1.49000e-01,  1.64000e-01,  1.71596e+02,  2.56933e+05,\n         4.00000e+00]])"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[8.09946714e-01, 3.16377171e-01, 1.00000000e+00, 3.07251166e+00,\n        1.00000000e+00, 7.47663551e-01, 1.00000000e+00, 1.00000000e+00,\n        1.00000000e+00, 9.85185185e-02, 6.78477354e-01, 9.84953276e-01,\n        1.00000000e+00],\n       [9.50266430e-01, 1.00000000e+00, 7.77777778e-01, 2.00019440e+00,\n        1.00000000e+00, 1.00000000e+00, 4.60887949e-03, 1.12352941e-01,\n        4.80546793e-01, 6.96296296e-01, 5.25006410e-01, 2.48052994e-01,\n        1.00000000e+00],\n       [5.22202487e-01, 5.98014888e-01, 5.55555556e-01, 1.24533437e+00,\n        1.00000000e+00, 6.69781931e-01, 4.89429175e-01, 0.00000000e+00,\n        3.52260778e-01, 3.77777778e-01, 9.71427073e-01, 9.93566416e-01,\n        7.50000000e-01],\n       [1.00000000e+00, 7.82878412e-01, 0.00000000e+00, 1.00000000e+00,\n        1.00000000e+00, 5.04672897e-01, 6.71247357e-02, 4.97647059e-05,\n        1.71398528e-01, 1.00000000e+00, 6.74007553e-01, 9.91803311e-01,\n        1.00000000e+00],\n       [6.35879218e-01, 7.58064516e-01, 2.22222222e-01, 1.89580093e+00,\n        0.00000000e+00, 7.07165109e-01, 5.44397463e-01, 2.75294118e-03,\n        1.56677182e-01, 3.03703704e-01, 1.00000000e+00, 1.00000000e+00,\n        1.00000000e+00]])"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Normalizing the data\n",
    "x_train = x_train / np.amax(x_train, axis=0)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork: \n",
    "    \n",
    "    def __init__(self):\n",
    "        # Setup Arch\n",
    "        self.inputs = 13\n",
    "        self.encode1 = 64\n",
    "        self.encode2 = 32\n",
    "\n",
    "        self.latent = 4\n",
    "\n",
    "        self.decode1 = 32\n",
    "        self.decode2 = 64\n",
    "        self.outputs = 13\n",
    "        \n",
    "        # Initialize Weights\n",
    "        self.weights1 = np.random.randn(self.inputs, self.encode1)\n",
    "        self.weights2 = np.random.randn(self.encode1, self.encode2)\n",
    "        self.weights3a = np.random.randn(self.encode2, self.latent)\n",
    "        self.weights3b = np.random.randn(self.encode2, self.latent)\n",
    "        self.weights4 = np.random.randn(self.latent, self.decode1)\n",
    "        self.weights5 = np.random.randn(self.decode1, self.decode2)\n",
    "        self.weights6 = np.random.randn(self.decode2, self.outputs)\n",
    "\n",
    "    def sigmoid(self, X):\n",
    "        return 1 / (1+np.exp(-X))\n",
    "    def sigmoidPrime(self, X):\n",
    "        sX = self.sigmoid(X)\n",
    "        return sX * (1-sX)\n",
    "\n",
    "    def relu(self, X):\n",
    "        return np.maximum(0,X)\n",
    "    def reluPrime(self, X):\n",
    "        X[X<=0] = 0\n",
    "        X[X>0] = 1\n",
    "\n",
    "    def softmax(self, X):\n",
    "        expo = np.exp(X)\n",
    "        expo_sum = np.sum(np.exp(X))\n",
    "        return expo/expo_sum\n",
    "\n",
    "    def feed_forward(self, X):\n",
    "        \"\"\"\n",
    "        Calculate the NN inference using feed forward.\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        self.hidden_sum1 = np.dot(X, self.weights1)\n",
    "        self.activated_hidden1 = self.relu(self.hidden_sum1)\n",
    "\n",
    "        self.hidden_sum2 = np.dot(self.activated_hidden1, self.weights2)\n",
    "        self.activated_hidden2 = self.relu(self.hidden_sum2)\n",
    "\n",
    "        self.z_log_sigma = np.dot(self.activated_hidden2, self.weights3a)\n",
    "        self.z_mean = np.dot(self.activated_hidden2, self.weights3b)\n",
    "\n",
    "        self.z_sample = self.z_mean + np.exp(self.z_log_sigma) * random.normal(loc=0, scale=1, size=(self.latent, ))\n",
    "        # random.normal(loc=0, scale=1, size=(4, )) # loc is mean | scale is std | size is shape\n",
    "\n",
    "        self.hidden_sum4 = np.dot(self.z_sample, self.weights4)\n",
    "        self.activated_hidden4 = self.relu(self.hidden_sum4)\n",
    "\n",
    "        self.hidden_sum5 = np.dot(self.activated_hidden4, self.weights5)\n",
    "        self.activated_hidden5 = self.relu(self.hidden_sum5)\n",
    "\n",
    "        self.hidden_sum6 = np.dot(self.activated_hidden5, self.weights6)\n",
    "\n",
    "        return self.hidden_sum6\n",
    "\n",
    "    def backward(self, X,o):\n",
    "        \"\"\"\n",
    "        Back prop thru the network\n",
    "        \"\"\"\n",
    "        self.mean_square_error = ((o-X) ** 2).mean()\n",
    "        self.reconstruction_loss = self.mean_square_error * self.inputs\n",
    "        self.kl_loss = (1+self.z_log_sigma-(self.z_mean**2)-np.exp(self.z_log_sigma)) * -0.5\n",
    "        self.o_error = (reconstruction_loss + kl_loss).mean()\n",
    "\n",
    "        self.o_delta = self.o_error * self.reluPrime(self.hidden_sum6)\n",
    "\n",
    "\n",
    "        # self.weights1 += \n",
    "        # self.weights2 += \n",
    "        # self.weights3a += \n",
    "        # self.weights3b += \n",
    "        # self.weights4 += \n",
    "        # self.weights5 += \n",
    "        # self.weights6 += \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        # self.o_error = y - o\n",
    "        \n",
    "        # # Apply derivative of sigmoid to error\n",
    "        # self.o_delta = self.o_error * self.sigmoidPrime(self.output_sum)\n",
    "        \n",
    "        # # z2 error: how much were our output layer weights off\n",
    "        # self.z2_error = self.o_delta.dot(self.weights2.T)\n",
    "        \n",
    "        # # z2 delta: how much were the weights off?\n",
    "        # self.z2_delta = self.z2_error*self.sigmoidPrime(self.hidden_sum)\n",
    "\n",
    "        # self.weights1 += X.T.dot(self.z2_delta) #Adjust first set (input => hidden) weights\n",
    "        # self.weights2 += self.activated_hidden.T.dot(self.o_delta) #adjust second set (hidden => output) weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reluPrime(X):\n",
    "    X[X<=0] = 0\n",
    "    X[X>0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "intput [0.80994671 0.31637717 1.         3.07251166 1.         0.74766355\n 1.         1.         1.         0.09851852 0.67847735 0.98495328\n 1.        ]\noutput [-8.06226197e+29 -6.83196746e+29 -1.12899827e+29 -3.88896915e+28\n -5.28620813e+29  1.32565895e+29  5.66417669e+29 -7.57264393e+29\n  1.09158132e+30 -2.47640496e+29  3.02869135e+29 -4.98384542e+29\n  2.18571433e+29]\n"
    }
   ],
   "source": [
    "nn = NeuralNetwork()\n",
    "output = nn.feed_forward(x_train[0])\n",
    "print(\"intput\", x_train[0])\n",
    "print(\"output\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'float' and 'NoneType'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-8bd1a58cb86d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mhidden_sum5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_sum5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# z2_delta =\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mz2_error\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mreluPrime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_sum5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "mean_square_error = ((output-x_train[0]) ** 2).mean()\n",
    "reconstruction_loss = mean_square_error * nn.inputs\n",
    "kl_loss = (1+nn.z_log_sigma-(nn.z_mean**2)-np.exp(nn.z_log_sigma)) * -0.5\n",
    "o_error = (reconstruction_loss + kl_loss).mean()\n",
    "o_delta = o_error * nn.hidden_sum6\n",
    "z2_error = o_delta.dot(nn.weights6.T)\n",
    "hidden_sum5 = nn.hidden_sum5\n",
    "# z2_delta = \n",
    "z2_error * reluPrime(hidden_sum5)\n",
    "\n",
    "\n",
    "# o_error * reluPrime(self.output_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.z2_delta = self.z2_error*self.sigmoidPrime(self.hidden_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_weights1 = np.random.randn(13, 64)\n",
    "test_weights2 = np.random.randn(64, 32)\n",
    "test_weights3 = np.random.randn(32, 4)\n",
    "test_weights4 = np.random.randn(4, 32)\n",
    "test_weights5 = np.random.randn(32, 64)\n",
    "test_weights6 = np.random.randn(64, 13)\n",
    "\n",
    "X1 = np.dot(x_train[0], test_weights1)\n",
    "X2 = np.maximum(0,X1)\n",
    "X3 = np.dot(X2, test_weights2)\n",
    "X4 = np.maximum(0,X3)\n",
    "X5 = np.dot(X4, test_weights3)\n",
    "X6 = X5\n",
    "X7 = np.dot(X6, test_weights4)\n",
    "X8 = np.maximum(0,X7)\n",
    "X9 = np.dot(X8, test_weights5)\n",
    "X10 = np.maximum(0,X9)\n",
    "X11 = np.dot(X10, test_weights6)\n",
    "X11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error calculation\n",
    "mean_square_error = ((output-x_train[0]) ** 2).mean()\n",
    "reconstruction_loss = mean_square_error * nn.inputs\n",
    "kl_loss = (1+nn.z_log_sigma-(nn.z_mean**2)-np.exp(nn.z_log_sigma)) * -0.5\n",
    "vae_loss = (reconstruction_loss + kl_loss).mean()\n",
    "vae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adam optimizer settings\n",
    "# Good default settings for the tested machine learning problems are alpha=0.001, beta1=0.9, beta2=0.999 and epsilon=10eâˆ’8"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "unit4env",
   "display_name": "unit4env (Python3)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}