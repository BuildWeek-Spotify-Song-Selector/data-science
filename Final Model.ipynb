{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder (VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Deep Learning\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras import backend as K\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "\n",
    "# Saving Model\n",
    "import os\n",
    "from pickle import dump, load\n",
    "\n",
    "# Making predictions\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Not used in current notebook\n",
    "# from keras.utils import plot_model\n",
    "# from keras.datasets import mnist\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data to pandas dataframe\n",
    "songs = pd.read_csv(\"song_list5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                   songid       artist                    track  danceability  \\\n0  5X4Qm0rVLcZeeO4tSDmBg3   Jack Bruce  Running Thro' Our Hands         0.456   \n1  1pNpt53PZPet9dvJN3RKGr   Prefuse 73        Parachute Panador         0.535   \n2  3oxz2oCzAWdPzA6In2zA5u  Pasion Vega   La Gata Bajo La Lluvia         0.294   \n3  05JGVUwt7XJk5FPqH0Wsch   Jonny Lang             Walking Away         0.563   \n4  3xdgCFMTn6ut8fZYxfAuR0         Skye         All the Promises         0.358   \n\n   energy  key  loudness  mode  speechiness  acousticness  instrumentalness  \\\n0   0.255  9.0   -15.805   1.0       0.0480       0.94600          0.170000   \n1   0.806  7.0   -10.289   1.0       0.0642       0.00436          0.019100   \n2   0.482  5.0    -6.406   1.0       0.0430       0.46300          0.000000   \n3   0.631  0.0    -5.144   1.0       0.0324       0.06350          0.000008   \n4   0.611  2.0    -9.752   0.0       0.0454       0.51500          0.000468   \n\n   liveness  valence    tempo  duration_ms  time_signature  \n0     0.951   0.0532  116.424     253067.0             4.0  \n1     0.457   0.3760   90.089      63733.0             4.0  \n2     0.335   0.2040  166.693     255280.0             3.0  \n3     0.163   0.5400  115.657     254827.0             4.0  \n4     0.149   0.1640  171.596     256933.0             4.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>songid</th>\n      <th>artist</th>\n      <th>track</th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>key</th>\n      <th>loudness</th>\n      <th>mode</th>\n      <th>speechiness</th>\n      <th>acousticness</th>\n      <th>instrumentalness</th>\n      <th>liveness</th>\n      <th>valence</th>\n      <th>tempo</th>\n      <th>duration_ms</th>\n      <th>time_signature</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5X4Qm0rVLcZeeO4tSDmBg3</td>\n      <td>Jack Bruce</td>\n      <td>Running Thro' Our Hands</td>\n      <td>0.456</td>\n      <td>0.255</td>\n      <td>9.0</td>\n      <td>-15.805</td>\n      <td>1.0</td>\n      <td>0.0480</td>\n      <td>0.94600</td>\n      <td>0.170000</td>\n      <td>0.951</td>\n      <td>0.0532</td>\n      <td>116.424</td>\n      <td>253067.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1pNpt53PZPet9dvJN3RKGr</td>\n      <td>Prefuse 73</td>\n      <td>Parachute Panador</td>\n      <td>0.535</td>\n      <td>0.806</td>\n      <td>7.0</td>\n      <td>-10.289</td>\n      <td>1.0</td>\n      <td>0.0642</td>\n      <td>0.00436</td>\n      <td>0.019100</td>\n      <td>0.457</td>\n      <td>0.3760</td>\n      <td>90.089</td>\n      <td>63733.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3oxz2oCzAWdPzA6In2zA5u</td>\n      <td>Pasion Vega</td>\n      <td>La Gata Bajo La Lluvia</td>\n      <td>0.294</td>\n      <td>0.482</td>\n      <td>5.0</td>\n      <td>-6.406</td>\n      <td>1.0</td>\n      <td>0.0430</td>\n      <td>0.46300</td>\n      <td>0.000000</td>\n      <td>0.335</td>\n      <td>0.2040</td>\n      <td>166.693</td>\n      <td>255280.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>05JGVUwt7XJk5FPqH0Wsch</td>\n      <td>Jonny Lang</td>\n      <td>Walking Away</td>\n      <td>0.563</td>\n      <td>0.631</td>\n      <td>0.0</td>\n      <td>-5.144</td>\n      <td>1.0</td>\n      <td>0.0324</td>\n      <td>0.06350</td>\n      <td>0.000008</td>\n      <td>0.163</td>\n      <td>0.5400</td>\n      <td>115.657</td>\n      <td>254827.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3xdgCFMTn6ut8fZYxfAuR0</td>\n      <td>Skye</td>\n      <td>All the Promises</td>\n      <td>0.358</td>\n      <td>0.611</td>\n      <td>2.0</td>\n      <td>-9.752</td>\n      <td>0.0</td>\n      <td>0.0454</td>\n      <td>0.51500</td>\n      <td>0.000468</td>\n      <td>0.149</td>\n      <td>0.1640</td>\n      <td>171.596</td>\n      <td>256933.0</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the columns I want into a features variable\n",
    "features = songs[[\n",
    "    \"danceability\", \"energy\", \"key\", \"loudness\", \"mode\", \"speechiness\", \n",
    "    \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\", \n",
    "    \"duration_ms\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(49985, 12)\narray([ 4.56000e-01,  2.55000e-01,  9.00000e+00, -1.58050e+01,\n        1.00000e+00,  4.80000e-02,  9.46000e-01,  1.70000e-01,\n        9.51000e-01,  5.32000e-02,  1.16424e+02,  2.53067e+05])\n"
    }
   ],
   "source": [
    "# View the feature data\n",
    "print(features.shape)\n",
    "pprint.pprint(features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the Scaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit transform the scaler on our feature data\n",
    "x_train = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the scaler to a new file\n",
    "# dump(scaler, open('scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(49985, 12)\narray([-0.47695143, -1.43616823,  1.03467011, -1.32564479,  0.70711739,\n       -0.34028656,  1.91669133, -0.14321669,  3.87500921, -1.70714343,\n       -0.17066299,  0.03404049])\n"
    }
   ],
   "source": [
    "# View the Scaled data\n",
    "print(x_train.shape)\n",
    "pprint.pprint(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reparameterization method for lambda layer\n",
    "# check this link out for research\n",
    "# https://stats.stackexchange.com/questions/199605/how-does-the-reparameterization-trick-for-vaes-work-and-why-is-it-important\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_sigma) * epsilon \n",
    "    #      z_mean + e^(.5 * z_log_sigma)     * ϵ\n",
    "    #                      φ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"Encoder\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nEncoder_Input (InputLayer)      (None, 12)           0                                            \n__________________________________________________________________________________________________\nEncoder_Dense1 (Dense)          (None, 512)          6656        Encoder_Input[0][0]              \n__________________________________________________________________________________________________\nEncoder_Dense2 (Dense)          (None, 256)          131328      Encoder_Dense1[0][0]             \n__________________________________________________________________________________________________\nEncoder_Dense3 (Dense)          (None, 128)          32896       Encoder_Dense2[0][0]             \n__________________________________________________________________________________________________\nz_mean (Dense)                  (None, 2)            258         Encoder_Dense3[0][0]             \n__________________________________________________________________________________________________\nz_log_sigma (Dense)             (None, 2)            258         Encoder_Dense3[0][0]             \n__________________________________________________________________________________________________\nz (Lambda)                      (None, 2)            0           z_mean[0][0]                     \n                                                                 z_log_sigma[0][0]                \n==================================================================================================\nTotal params: 171,396\nTrainable params: 171,396\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "# build encoder model\n",
    "encoder_input = Input(shape=(12,), name='Encoder_Input')\n",
    "\n",
    "encoder_dense1 = Dense(512, activation='relu', name='Encoder_Dense1')(encoder_input)\n",
    "encoder_dense2 = Dense(256, activation='relu', name='Encoder_Dense2')(encoder_dense1)\n",
    "encoder_dense3 = Dense(128, activation='relu', name='Encoder_Dense3')(encoder_dense2)\n",
    "\n",
    "# we need 2 Latent Sized Dense Layers for reparameterization\n",
    "z_mean = Dense(2, name='z_mean')(encoder_dense3)\n",
    "z_log_sigma = Dense(2, name='z_log_sigma')(encoder_dense3)\n",
    "\n",
    "# Use Lambda layer to apply the sampling function (Reparameterization)\n",
    "z = Lambda(sampling, output_shape=(2,), name='z')([z_mean, z_log_sigma])\n",
    "\n",
    "# instantiate encoder model\n",
    "encoder = Model(encoder_input, [z_mean, z_log_sigma, z], name='Encoder')\n",
    "encoder.summary()\n",
    "# plot_model(encoder, to_file='vae_mlp_encoder.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"Decoder\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nz_sampling (InputLayer)      (None, 2)                 0         \n_________________________________________________________________\nDecoder_Dense1 (Dense)       (None, 128)               384       \n_________________________________________________________________\nDecoder_Dense2 (Dense)       (None, 256)               33024     \n_________________________________________________________________\nDecoder_Dense3 (Dense)       (None, 512)               131584    \n_________________________________________________________________\nDecoder_Output (Dense)       (None, 12)                6156      \n=================================================================\nTotal params: 171,148\nTrainable params: 171,148\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# build decoder model\n",
    "latent_inputs = Input(shape=(2,), name='z_sampling')\n",
    "\n",
    "decoder_dense1 = Dense(128, activation='relu', name='Decoder_Dense1')(latent_inputs)\n",
    "decoder_dense2 = Dense(256, activation='relu', name='Decoder_Dense2')(decoder_dense1)\n",
    "decoder_dense3 = Dense(512, activation='relu', name='Decoder_Dense3')(decoder_dense2)\n",
    "\n",
    "decoder_output = Dense(12, name='Decoder_Output')(decoder_dense3)\n",
    "\n",
    "# instantiate decoder model\n",
    "decoder = Model(latent_inputs, decoder_output, name='Decoder')\n",
    "decoder.summary()\n",
    "# plot_model(decoder, to_file='vae_mlp_decoder.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"VAE_Model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nEncoder_Input (InputLayer)   (None, 12)                0         \n_________________________________________________________________\nEncoder (Model)              [(None, 2), (None, 2), (N 171396    \n_________________________________________________________________\nDecoder (Model)              (None, 12)                171148    \n=================================================================\nTotal params: 342,544\nTrainable params: 342,544\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(encoder_input)[2])\n",
    "vae = Model(encoder_input, outputs, name='VAE_Model')\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"VAE_Model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nEncoder_Input (InputLayer)   (None, 12)                0         \n_________________________________________________________________\nEncoder (Model)              [(None, 2), (None, 2), (N 171396    \n_________________________________________________________________\nDecoder (Model)              (None, 12)                171148    \n=================================================================\nTotal params: 342,544\nTrainable params: 342,544\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# Reconstuction Loss Function\n",
    "reconstruction_loss = mse(encoder_input, outputs)\n",
    "reconstruction_loss *= 12\n",
    "# k1 Loss Function\n",
    "kl_loss = 1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "vae.summary()\n",
    "# plot_model(vae,\n",
    "#             to_file='vae_mlp.png',\n",
    "#             show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/50\n49985/49985 [==============================] - 9s 174us/step - loss: 9.3415\nEpoch 2/50\n49985/49985 [==============================] - 8s 167us/step - loss: 8.9006\nEpoch 3/50\n49985/49985 [==============================] - 8s 168us/step - loss: 8.7383\nEpoch 4/50\n49985/49985 [==============================] - 9s 171us/step - loss: 8.6680\nEpoch 5/50\n49985/49985 [==============================] - 8s 168us/step - loss: 8.6164\nEpoch 6/50\n49985/49985 [==============================] - 8s 170us/step - loss: 8.5863\nEpoch 7/50\n49985/49985 [==============================] - 9s 171us/step - loss: 8.5367\nEpoch 8/50\n49985/49985 [==============================] - 9s 170us/step - loss: 8.5386\nEpoch 9/50\n49985/49985 [==============================] - 8s 170us/step - loss: 8.4635\nEpoch 10/50\n49985/49985 [==============================] - 9s 170us/step - loss: 8.4322\nEpoch 11/50\n49985/49985 [==============================] - 8s 169us/step - loss: 8.4232\nEpoch 12/50\n49985/49985 [==============================] - 7s 150us/step - loss: 8.4017\nEpoch 13/50\n49985/49985 [==============================] - 7s 149us/step - loss: 8.3960\nEpoch 14/50\n49985/49985 [==============================] - 9s 171us/step - loss: 8.3719\nEpoch 15/50\n49985/49985 [==============================] - 9s 173us/step - loss: 8.3629\nEpoch 16/50\n49985/49985 [==============================] - 8s 170us/step - loss: 8.3773\nEpoch 17/50\n49985/49985 [==============================] - 9s 173us/step - loss: 8.3442\nEpoch 18/50\n49985/49985 [==============================] - 9s 178us/step - loss: 8.3205\nEpoch 19/50\n49985/49985 [==============================] - 8s 169us/step - loss: 8.3302\nEpoch 20/50\n49985/49985 [==============================] - 8s 166us/step - loss: 8.3359\nEpoch 21/50\n49985/49985 [==============================] - 8s 168us/step - loss: 8.3111\nEpoch 22/50\n49985/49985 [==============================] - 8s 169us/step - loss: 8.2983\nEpoch 23/50\n49985/49985 [==============================] - 8s 168us/step - loss: 8.2961\nEpoch 24/50\n49920/49985 [============================>.] - ETA: 0s - loss: 8.27449985/49985 [==============================] - 9s 174us/step - loss: 8.2735\nEpoch 25/50\n49985/49985 [==============================] - 9s 176us/step - loss: 8.2731\nEpoch 26/50\n49985/49985 [==============================] - 9s 172us/step - loss: 8.2634\nEpoch 27/50\n49985/49985 [==============================] - 9s 174us/step - loss: 8.2351\nEpoch 28/50\n49985/49985 [==============================] - 8s 170us/step - loss: 8.2486\nEpoch 29/50\n49985/49985 [==============================] - 9s 173us/step - loss: 8.2454\nEpoch 30/50\n49985/49985 [==============================] - 9s 187us/step - loss: 8.2698\nEpoch 31/50\n49985/49985 [==============================] - 9s 181us/step - loss: 8.2598\nEpoch 32/50\n49985/49985 [==============================] - 10s 201us/step - loss: 8.2362\nEpoch 33/50\n49985/49985 [==============================] - 9s 186us/step - loss: 8.2445\nEpoch 34/50\n49985/49985 [==============================] - 7s 137us/step - loss: 8.2339\nEpoch 35/50\n49985/49985 [==============================] - 7s 133us/step - loss: 8.2223\nEpoch 36/50\n49985/49985 [==============================] - 8s 156us/step - loss: 8.2261\nEpoch 37/50\n49985/49985 [==============================] - 8s 160us/step - loss: 8.2295\nEpoch 38/50\n49985/49985 [==============================] - 7s 135us/step - loss: 8.2282\nEpoch 39/50\n49985/49985 [==============================] - 6s 128us/step - loss: 8.2246\nEpoch 40/50\n49985/49985 [==============================] - 8s 168us/step - loss: 8.2349\nEpoch 41/50\n49985/49985 [==============================] - 9s 170us/step - loss: 8.2074\nEpoch 42/50\n49985/49985 [==============================] - 7s 133us/step - loss: 8.2156\nEpoch 43/50\n49985/49985 [==============================] - 7s 147us/step - loss: 8.1961\nEpoch 44/50\n49985/49985 [==============================] - 8s 170us/step - loss: 8.2018\nEpoch 45/50\n49985/49985 [==============================] - 7s 133us/step - loss: 8.1869\nEpoch 46/50\n49985/49985 [==============================] - 7s 146us/step - loss: 8.1807\nEpoch 47/50\n49985/49985 [==============================] - 8s 164us/step - loss: 8.1852\nEpoch 48/50\n49985/49985 [==============================] - 8s 169us/step - loss: 8.2005\nEpoch 49/50\n49985/49985 [==============================] - 7s 144us/step - loss: 8.1741\nEpoch 50/50\n49985/49985 [==============================] - 7s 145us/step - loss: 8.1934\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.callbacks.History at 0x18637476c88>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "vae.fit(x_train,\n",
    "        epochs=3, # Set down to 3 for Demo Purposes\n",
    "        batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current Best Loss 8.1934\n",
    "# dump(encoder, open('VAE_Encoder.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the model\n",
    "encoder_test = load(open('VAE_Encoder.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[-0.03490391, -2.8897223 ],\n       [-0.2080349 ,  0.02317297],\n       [ 0.30692878,  0.01386828],\n       ...,\n       [-1.6854535 , -0.79184806],\n       [-0.77382445,  2.0584621 ],\n       [ 2.3800442 , -0.77051663]], dtype=float32)"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# get our latent features\n",
    "preds = encoder_test.predict(x_train)\n",
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the nearest neighbors to our data\n",
    "n_neighbors = 5\n",
    "nbrs = NearestNeighbors(n_neighbors=(n_neighbors+1), algorithm='ball_tree').fit(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making our prediction\n",
    "distances, indices = nbrs.kneighbors(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                       songid              artist                    track  \\\n0      5X4Qm0rVLcZeeO4tSDmBg3          Jack Bruce  Running Thro' Our Hands   \n48250  4lcMjDKPJdsXGeP97mnbkJ         Bright Eyes          The Biggest Lie   \n49381  0mTPxzmCSRpjPxJLqyLEQA        Mose Allison    How Much Truth (Live)   \n2477   7EWWSCdsJXQWvk1lRMgO4y  Kris Kristofferson              The Captive   \n39968  1Yj4O4nnZPcNuPL2tmOxUZ    The Irish Tenors               Galway Bay   \n31110  5AwcHzpib6rajOz4bm1Ytn         Slapp Happy     Small Hands Of Stone   \n\n       danceability  energy   key  loudness  mode  speechiness  acousticness  \\\n0             0.456   0.255   9.0   -15.805   1.0       0.0480         0.946   \n48250         0.386   0.102   0.0   -19.300   1.0       0.0626         0.894   \n49381         0.519   0.100   1.0   -18.189   1.0       0.0676         0.944   \n2477          0.519   0.135   2.0   -16.851   1.0       0.0353         0.812   \n39968         0.284   0.291  10.0   -14.479   1.0       0.0511         0.858   \n31110         0.520   0.239  10.0   -13.753   1.0       0.0348         0.879   \n\n       instrumentalness  liveness  valence    tempo  duration_ms  \\\n0              0.170000     0.951   0.0532  116.424     253067.0   \n48250          0.000327     0.891   0.3250  152.483     168067.0   \n49381          0.000229     0.717   0.2390  137.507     170640.0   \n2477           0.000014     0.686   0.3120  109.331     195013.0   \n39968          0.000028     0.828   0.2370   89.506     175733.0   \n31110          0.000003     0.681   0.0736  110.381     203080.0   \n\n       time_signature  \n0                 4.0  \n48250             4.0  \n49381             4.0  \n2477              4.0  \n39968             4.0  \n31110             3.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>songid</th>\n      <th>artist</th>\n      <th>track</th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>key</th>\n      <th>loudness</th>\n      <th>mode</th>\n      <th>speechiness</th>\n      <th>acousticness</th>\n      <th>instrumentalness</th>\n      <th>liveness</th>\n      <th>valence</th>\n      <th>tempo</th>\n      <th>duration_ms</th>\n      <th>time_signature</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5X4Qm0rVLcZeeO4tSDmBg3</td>\n      <td>Jack Bruce</td>\n      <td>Running Thro' Our Hands</td>\n      <td>0.456</td>\n      <td>0.255</td>\n      <td>9.0</td>\n      <td>-15.805</td>\n      <td>1.0</td>\n      <td>0.0480</td>\n      <td>0.946</td>\n      <td>0.170000</td>\n      <td>0.951</td>\n      <td>0.0532</td>\n      <td>116.424</td>\n      <td>253067.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>48250</th>\n      <td>4lcMjDKPJdsXGeP97mnbkJ</td>\n      <td>Bright Eyes</td>\n      <td>The Biggest Lie</td>\n      <td>0.386</td>\n      <td>0.102</td>\n      <td>0.0</td>\n      <td>-19.300</td>\n      <td>1.0</td>\n      <td>0.0626</td>\n      <td>0.894</td>\n      <td>0.000327</td>\n      <td>0.891</td>\n      <td>0.3250</td>\n      <td>152.483</td>\n      <td>168067.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>49381</th>\n      <td>0mTPxzmCSRpjPxJLqyLEQA</td>\n      <td>Mose Allison</td>\n      <td>How Much Truth (Live)</td>\n      <td>0.519</td>\n      <td>0.100</td>\n      <td>1.0</td>\n      <td>-18.189</td>\n      <td>1.0</td>\n      <td>0.0676</td>\n      <td>0.944</td>\n      <td>0.000229</td>\n      <td>0.717</td>\n      <td>0.2390</td>\n      <td>137.507</td>\n      <td>170640.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>2477</th>\n      <td>7EWWSCdsJXQWvk1lRMgO4y</td>\n      <td>Kris Kristofferson</td>\n      <td>The Captive</td>\n      <td>0.519</td>\n      <td>0.135</td>\n      <td>2.0</td>\n      <td>-16.851</td>\n      <td>1.0</td>\n      <td>0.0353</td>\n      <td>0.812</td>\n      <td>0.000014</td>\n      <td>0.686</td>\n      <td>0.3120</td>\n      <td>109.331</td>\n      <td>195013.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>39968</th>\n      <td>1Yj4O4nnZPcNuPL2tmOxUZ</td>\n      <td>The Irish Tenors</td>\n      <td>Galway Bay</td>\n      <td>0.284</td>\n      <td>0.291</td>\n      <td>10.0</td>\n      <td>-14.479</td>\n      <td>1.0</td>\n      <td>0.0511</td>\n      <td>0.858</td>\n      <td>0.000028</td>\n      <td>0.828</td>\n      <td>0.2370</td>\n      <td>89.506</td>\n      <td>175733.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>31110</th>\n      <td>5AwcHzpib6rajOz4bm1Ytn</td>\n      <td>Slapp Happy</td>\n      <td>Small Hands Of Stone</td>\n      <td>0.520</td>\n      <td>0.239</td>\n      <td>10.0</td>\n      <td>-13.753</td>\n      <td>1.0</td>\n      <td>0.0348</td>\n      <td>0.879</td>\n      <td>0.000003</td>\n      <td>0.681</td>\n      <td>0.0736</td>\n      <td>110.381</td>\n      <td>203080.0</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# Results\n",
    "songs.iloc[indices[0]]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "unit4env",
   "display_name": "unit4env (Python3)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}